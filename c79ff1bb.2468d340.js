(window.webpackJsonp=window.webpackJsonp||[]).push([[41],{143:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return r})),n.d(t,"metadata",(function(){return c})),n.d(t,"rightToc",(function(){return l})),n.d(t,"default",(function(){return u}));var a=n(2),o=n(6),i=(n(0),n(156)),r={title:"Semi-automatic annotation with CVAT",sidebar_label:"Automatic annotation",description:"Onepanel use case - computer vision automatic annotation"},c={id:"getting-started/use-cases/computervision/annotation/cvat/cvat_automatic_annotation",title:"Semi-automatic annotation with CVAT",description:"Onepanel use case - computer vision automatic annotation",source:"@site/docs/getting-started/use-cases/computervision/annotation/cvat/cvat_automatic_annotation.md",permalink:"/docs/getting-started/use-cases/computervision/annotation/cvat/cvat_automatic_annotation",editUrl:"https://github.com/onepanelio/core-docs/tree/master/docs/getting-started/use-cases/computervision/annotation/cvat/cvat_automatic_annotation.md",sidebar_label:"Automatic annotation",sidebar:"gettingStarted",previous:{title:"Quick start",permalink:"/docs/getting-started/use-cases/computervision/annotation/cvat/cvat_quick_guide"},next:{title:"Creating annotation models on CVAT",permalink:"/docs/getting-started/use-cases/computervision/annotation/cvat/cvat_annotation_model"}},l=[{value:"Semi-automatic annotation on CVAT",id:"semi-automatic-annotation-on-cvat",children:[]},{value:"Uploading your model on CVAT",id:"uploading-your-model-on-cvat",children:[]},{value:"Semi-automatic annotation of bounding boxes and polygon masks",id:"semi-automatic-annotation-of-bounding-boxes-and-polygon-masks",children:[]},{value:"Hardware requirements",id:"hardware-requirements",children:[]}],s={rightToc:l};function u(e){var t=e.components,n=Object(o.a)(e,["components"]);return Object(i.b)("wrapper",Object(a.a)({},s,n,{components:t,mdxType:"MDXLayout"}),Object(i.b)("h2",{id:"semi-automatic-annotation-on-cvat"},"Semi-automatic annotation on CVAT"),Object(i.b)("p",null,"You can use your TensorFlow models for Object Detection and Semantic Segmentation to pre-annotate your data. This can save you a lot of time since you don't have to annotate images from scratch. On Onepanel, you can leverage these features to pre-annotate your bounding boxes or polygon masks. You can also use Object Tracking to track objects in a sequence of frames."),Object(i.b)("h2",{id:"uploading-your-model-on-cvat"},"Uploading your model on CVAT"),Object(i.b)("p",null,"Before using any type of semi-automatic annotation, you will need to upload your model on CVAT Model Manager by clicking on Models. To upload your model, go to your CVAT dashboard and click on Models. A pop up window will appear where you can give a name to your model, select the source of your files (local or cloud), and select files as shown below."),Object(i.b)("p",null,Object(i.b)("img",Object(a.a)({parentName:"p"},{src:"/img/upload_model.PNG",alt:"Upload Model"}))),Object(i.b)("p",null," For TF Object Detection API and MaskRCNN, you will need two files- model and classes.csv. For TF Object Detection API, the model should be Tensorflow Frozen Graph (",Object(i.b)("inlineCode",{parentName:"p"},".pb"),"). For MaskRCNN, it should be Keras model (",Object(i.b)("inlineCode",{parentName:"p"},".h5"),")."),Object(i.b)("h2",{id:"semi-automatic-annotation-of-bounding-boxes-and-polygon-masks"},"Semi-automatic annotation of bounding boxes and polygon masks"),Object(i.b)("ol",null,Object(i.b)("li",{parentName:"ol"},"The first step is to upload your model on CVAT or use our default models which are available on CVAT. "),Object(i.b)("li",{parentName:"ol"},"Find Actions button for the task on which you want to run pre-annotation.\n",Object(i.b)("img",Object(a.a)({parentName:"li"},{src:"/img/select_automatic_annotation.png",alt:"Click Actions"}))),Object(i.b)("li",{parentName:"ol"},"Click on Automatic Annotation, a pop up will appear where you can select the model you want to use for pre-annotation. Once you select the model, an automatic class mapping will appear, you can modify it if you want. Please note that the class mapping will appear for custom models only, not for default models.\n",Object(i.b)("img",Object(a.a)({parentName:"li"},{src:"/img/start_automatic_annotation.png",alt:"Class Mapping"}))),Object(i.b)("li",{parentName:"ol"},"Once done, click on Start. You will see a progress bar as shown below. Once it is done, you can go into your task and check out the pre-annotation. Sometimes, these new annotations might not reflect in your task automatically, you may have to refresh your page.\n",Object(i.b)("img",Object(a.a)({parentName:"li"},{src:"/img/automatic_annotation_running.png",alt:"Automatic Annotation Running"})))),Object(i.b)("h2",{id:"hardware-requirements"},"Hardware requirements"),Object(i.b)("p",null,"For training a model(Execute training Workflow), you can choose any GPU machine from the list. All of our models will work on any of the GPU machine. But if you want to train it faster, then we suggest you select machines with multiple GPUs (i.e 8 V100)."),Object(i.b)("p",null,"Please find the table bewlo which details machine type with the corresponding runtime to perform pre-annotations.\nFor this test, we used a task with ",Object(i.b)("strong",{parentName:"p"},"3550 images (2GB)")," to perform pre-annotations."),Object(i.b)("table",null,Object(i.b)("thead",{parentName:"table"},Object(i.b)("tr",{parentName:"thead"},Object(i.b)("th",Object(a.a)({parentName:"tr"},{align:null}),"Machine \xa0 \xa0"),Object(i.b)("th",Object(a.a)({parentName:"tr"},{align:null}),"Time \xa0 \xa0"))),Object(i.b)("tbody",{parentName:"table"},Object(i.b)("tr",{parentName:"tbody"},Object(i.b)("td",Object(a.a)({parentName:"tr"},{align:null}),"K80 \xa0 \xa0 \xa0 \xa0"),Object(i.b)("td",Object(a.a)({parentName:"tr"},{align:null}),"160 minutes \xa0")),Object(i.b)("tr",{parentName:"tbody"},Object(i.b)("td",Object(a.a)({parentName:"tr"},{align:null}),"V100 \xa0 \xa0 \xa0 \xa0"),Object(i.b)("td",Object(a.a)({parentName:"tr"},{align:null}),"80 minutes")),Object(i.b)("tr",{parentName:"tbody"},Object(i.b)("td",Object(a.a)({parentName:"tr"},{align:null}),"V100 x 4 \xa0 \xa0"),Object(i.b)("td",Object(a.a)({parentName:"tr"},{align:null}),"21 minutes")))),Object(i.b)("p",null,"Run time depends on factors such as ",Object(i.b)("strong",{parentName:"p"},"model, number of images, type of machine.")),Object(i.b)("p",null,"The above data was generated for ssd-mobilenet-v2 model which is the model we suggest to use in normal circumstances. If you have complex annotations and want to use faster-rcnn based model, then it might take slightly more time. But note that it won\u2019t significantly alter the data presented above."),Object(i.b)("p",null,"The other factor is image compression. By default, CVAT compresses images by 50%. We did some testing to find out if we use original images (without compression) then how much time it will take."),Object(i.b)("p",null,"It turns out that if you use the original images without compression, your pre-annotation time will be increased by ~5-6% of that of 50% compressed images. So in the above table, if you use images without compression and use a V100, it will take 84 minutes instead of 80 minutes. Please note that this compression does not affect annotation in any way."),Object(i.b)("p",null,"Note that this data was calculated on 3550 images (1280 x 960)(total size=2GB), so if your data size is different you can easily extrapolate the data from the above table. For example, if you have 10gb of images then ideally it will take around 400 minutes on a V100 GPU. "),Object(i.b)("p",null,"If the resolution of your images is slightly different, then it won\u2019t affect run time significantly. In fact, if the difference is ~200 pixels then it won\u2019t change at all, generally."),Object(i.b)("p",null,"If you still have any questions, feel free to reach out to us at ",Object(i.b)("a",Object(a.a)({parentName:"p"},{href:"mailto:info@onepanel.io"}),"info@onepanel.io")))}u.isMDXComponent=!0},156:function(e,t,n){"use strict";n.d(t,"a",(function(){return m})),n.d(t,"b",(function(){return d}));var a=n(0),o=n.n(a);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function c(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=o.a.createContext({}),u=function(e){var t=o.a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):c(c({},t),e)),n},m=function(e){var t=u(e.components);return o.a.createElement(s.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return o.a.createElement(o.a.Fragment,{},t)}},b=o.a.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,r=e.parentName,s=l(e,["components","mdxType","originalType","parentName"]),m=u(n),b=a,d=m["".concat(r,".").concat(b)]||m[b]||p[b]||i;return n?o.a.createElement(d,c(c({ref:t},s),{},{components:n})):o.a.createElement(d,c({ref:t},s))}));function d(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,r=new Array(i);r[0]=b;var c={};for(var l in t)hasOwnProperty.call(t,l)&&(c[l]=t[l]);c.originalType=e,c.mdxType="string"==typeof e?e:a,r[1]=c;for(var s=2;s<i;s++)r[s]=n[s];return o.a.createElement.apply(null,r)}return o.a.createElement.apply(null,n)}b.displayName="MDXCreateElement"}}]);